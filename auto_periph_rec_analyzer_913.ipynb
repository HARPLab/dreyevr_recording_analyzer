{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3794cc2a-5c11-416c-bdc9-b0bf4502f089",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibmm import EyeClassifier\n",
    "# from ibmm_online import EyeClassifierOnline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "from parser_utils import read_periph_recording, parse_new_dreyevr_rec\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "022acadb-3082-415a-890e-118c6eca0cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cfa789f-6a22-4d55-8896-a875242880e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ibmm import EyeClassifier\n",
    "from ibmm_online import EyeClassifierOnline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2be9b012-f6e3-47f9-be77-a0374f193ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO if there are misses at the very beginning of some recording files, we should get rid of them \n",
    "# e.g. esther11/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587a4402-03ec-4dd8-8ac7-ea0b00209f52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44849135-c5a9-46d3-8c32-cdcf3b05e058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hits_and_misses_test = hits_and_misses.copy()\n",
    "# mctr=0\n",
    "# while hits_and_misses_test[0][1] is False:\n",
    "#     mctr += 1\n",
    "#     hits_and_misses_test = hits_and_misses_test[1:]\n",
    "#     print(mctr)\n",
    "# print(len(hits_and_misses), len(hits_and_misses_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "952798ee-31ee-4e69-bb6d-01b102aef521",
   "metadata": {},
   "outputs": [],
   "source": [
    "bRemoveLeadingMisses = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28314e83-658a-4586-bc64-afa258ca520c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================\n",
      "C://carla//carla.periph//RecordingTxts\\abhijat\\aj-32.txt\n",
      "====================================\n",
      "already parsed\n",
      "====================================\n",
      "C://carla//carla.periph//RecordingTxts\\abhijat\\aj-54.txt\n",
      "====================================\n",
      "already parsed\n",
      "====================================\n",
      "C://carla//carla.periph//RecordingTxts\\abhijat\\aj-55.txt\n",
      "====================================\n",
      "already parsed\n",
      "====================================\n",
      "C://carla//carla.periph//RecordingTxts\\dexter\\dexter11.txt\n",
      "====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 8325/8325 [00:26<00:00, 318.80it/s]\n",
      "19it [00:01, 18.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/19 hits with a 0.7183116666666617s average reaction time\n",
      "17/19 valid targets\n",
      "17 fixation onsets, 0 sacc, 0 noise\n",
      "done writing  temp_data\\all_leading_misses\\dexter11_OFDvEcc.pkl\n",
      "====================================\n",
      "C://carla//carla.periph//RecordingTxts\\dexter\\dexter21.txt\n",
      "====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 6437/6437 [00:17<00:00, 369.58it/s]\n",
      "15it [00:00, 23.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/15 hits with a 0.5579000000000024s average reaction time\n",
      "15/15 valid targets\n",
      "12 fixation onsets, 2 sacc, 1 noise\n",
      "done writing  temp_data\\all_leading_misses\\dexter21_OFDvEcc.pkl\n",
      "====================================\n",
      "C://carla//carla.periph//RecordingTxts\\dexter\\dexter32.txt\n",
      "====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 9105/9105 [00:30<00:00, 301.93it/s]\n",
      "20it [00:00, 22.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/20 hits with a 0.8377133333333364s average reaction time\n",
      "20/20 valid targets\n",
      "19 fixation onsets, 0 sacc, 1 noise\n",
      "done writing  temp_data\\all_leading_misses\\dexter32_OFDvEcc.pkl\n",
      "====================================\n",
      "C://carla//carla.periph//RecordingTxts\\dexter\\dexter54.txt\n",
      "====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 8909/8909 [00:29<00:00, 304.20it/s]\n",
      "20it [00:01, 16.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/20 hits with a 0.8443153846153854s average reaction time\n",
      "19/20 valid targets\n",
      "18 fixation onsets, 1 sacc, 0 noise\n",
      "done writing  temp_data\\all_leading_misses\\dexter54_OFDvEcc.pkl\n",
      "====================================\n",
      "C://carla//carla.periph//RecordingTxts\\dexter\\dexter55.txt\n",
      "====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 5593/5593 [00:14<00:00, 377.97it/s]\n",
      "12it [00:00, 44.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/12 hits with a 0.6724300000000005s average reaction time\n",
      "11/12 valid targets\n",
      "10 fixation onsets, 1 sacc, 0 noise\n",
      "done writing  temp_data\\all_leading_misses\\dexter55_OFDvEcc.pkl\n",
      "====================================\n",
      "C://carla//carla.periph//RecordingTxts\\esther\\esther11.txt\n",
      "====================================\n",
      "already parsed\n",
      "====================================\n",
      "C://carla//carla.periph//RecordingTxts\\esther\\esther21.txt\n",
      "====================================\n",
      "already parsed\n",
      "====================================\n",
      "C://carla//carla.periph//RecordingTxts\\esther\\esther32.txt\n",
      "====================================\n",
      "already parsed\n",
      "====================================\n",
      "C://carla//carla.periph//RecordingTxts\\esther\\esther54.txt\n",
      "====================================\n",
      "already parsed\n",
      "====================================\n",
      "C://carla//carla.periph//RecordingTxts\\esther\\esther55.txt\n",
      "====================================\n",
      "already parsed\n",
      "====================================\n",
      "C://carla//carla.periph//RecordingTxts\\george\\george-11.txt\n",
      "====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 10857/10857 [00:02<00:00, 3885.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================\n",
      "C://carla//carla.periph//RecordingTxts\\george\\george-32.txt\n",
      "====================================\n",
      "already parsed\n",
      "====================================\n",
      "C://carla//carla.periph//RecordingTxts\\george\\george-54.txt\n",
      "====================================\n",
      "already parsed\n",
      "====================================\n",
      "C://carla//carla.periph//RecordingTxts\\george\\george-55.txt\n",
      "====================================\n",
      "already parsed\n",
      "====================================\n",
      "C://carla//carla.periph//RecordingTxts\\jacob\\jacob21.txt\n",
      "====================================\n",
      "already parsed\n",
      "====================================\n",
      "C://carla//carla.periph//RecordingTxts\\jacob\\jacob54.txt\n",
      "====================================\n",
      "already parsed\n",
      "====================================\n",
      "C://carla//carla.periph//RecordingTxts\\jacob\\jacob55.txt\n",
      "====================================\n",
      "already parsed\n",
      "====================================\n",
      "C://carla//carla.periph//RecordingTxts\\tab\\tab11.txt\n",
      "====================================\n",
      "already parsed\n",
      "====================================\n",
      "C://carla//carla.periph//RecordingTxts\\tab\\tab21.txt\n",
      "====================================\n",
      "already parsed\n",
      "====================================\n",
      "C://carla//carla.periph//RecordingTxts\\tab\\tab32.txt\n",
      "====================================\n",
      "already parsed\n",
      "====================================\n",
      "C://carla//carla.periph//RecordingTxts\\tab\\tab54.txt\n",
      "====================================\n",
      "already parsed\n",
      "====================================\n",
      "C://carla//carla.periph//RecordingTxts\\tab\\tab55.txt\n",
      "====================================\n",
      "already parsed\n",
      "====================================\n",
      "C://carla//carla.periph//RecordingTxts\\tanmay\\tanmay21.txt\n",
      "====================================\n",
      "already parsed\n",
      "====================================\n",
      "C://carla//carla.periph//RecordingTxts\\tanmay\\tanmay32.txt\n",
      "====================================\n",
      "already parsed\n",
      "====================================\n",
      "C://carla//carla.periph//RecordingTxts\\tanmay\\tanmay54.txt\n",
      "====================================\n",
      "already parsed\n",
      "====================================\n",
      "C://carla//carla.periph//RecordingTxts\\tanmay\\tanmay55.txt\n",
      "====================================\n",
      "already parsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "recfile_dir = \"C://carla//carla.periph//RecordingTxts//*//*.txt\"\n",
    "\n",
    "total_leading_misses_removed = 0\n",
    "\n",
    "for path_to_recording in glob(recfile_dir):\n",
    "    try:\n",
    "        print(\"====================================\")\n",
    "        print(path_to_recording)\n",
    "        print(\"====================================\")\n",
    "        recording_name = Path(path_to_recording).stem\n",
    "        recdf_pklname = Path(\"temp_data\").joinpath(recording_name+\".pkl\")\n",
    "        if bRemoveLeadingMisses:\n",
    "            graph_data_filename = Path(\"temp_data/no_leading_misses\").joinpath(recording_name+\"_OFDvEcc.pkl\")\n",
    "        else:\n",
    "            graph_data_filename = Path(\"temp_data/all_leading_misses\").joinpath(recording_name+\"_OFDvEcc.pkl\")\n",
    "        if Path(graph_data_filename).exists():\n",
    "            print(\"already parsed\")\n",
    "            continue\n",
    "\n",
    "        df = parse_new_dreyevr_rec(path_to_recording, False)\n",
    "        df1 = df.copy()\n",
    "        # find the indices where lights came on and went off\n",
    "        lighton_rows = df1[\"LightOn\"].diff().fillna(0)==1\n",
    "        lightoff_rows = df1[\"LightOn\"].diff().fillna(0)==-1\n",
    "        df1[lighton_rows].head()\n",
    "        lighton_idcs = df1[lighton_rows].index\n",
    "        num_targets_spawned = sum(lighton_rows)\n",
    "        # find the indices where the button was pressed\n",
    "        buttonPress_rows = df1[\"ButtonPressed\"].diff().fillna(0)==1\n",
    "        buttonRelease_rows = df1[\"ButtonPressed\"].diff().fillna(0)==-1\n",
    "        num_button_presses = sum(buttonPress_rows)\n",
    "        # print(\"{} targets spawned\".format(num_targets_spawned))\n",
    "        # print(\"{} responses recorded\".format(num_button_presses)) # may or may not be all accurate responses that correspond to targets?\n",
    "        # for every light appearance\n",
    "        # find the nearest button press, before the next target appearance\n",
    "        max_reaction_time_allowed = 5 #seconds\n",
    "        time_offsets = []\n",
    "        hits_and_misses = []\n",
    "        for idx_num, lighton_idx in tqdm(enumerate(lighton_idcs)):\n",
    "            # while not found_buttonpress or lighton_idcs[idx_num+1]:\n",
    "            offset = 0\n",
    "            target_tuple = (df1.loc[lighton_idx], False)\n",
    "            while lighton_idx+offset < max(df1.index):\n",
    "                time_offset = df1.loc[lighton_idx+offset, \"TimeElapsed\"] - df1.loc[lighton_idx, \"TimeElapsed\"]   \n",
    "                if (df1.loc[lighton_idx+offset, \"ButtonPressed\"] == 1):\n",
    "                    # print(\"{0:1.2f}s\".format(time_offset))\n",
    "                    time_offsets += [time_offset]\n",
    "                    target_tuple = (df1.loc[lighton_idx], df1.loc[lighton_idx+offset])\n",
    "                    break\n",
    "                else:\n",
    "                    if time_offset > max_reaction_time_allowed:\n",
    "                        break\n",
    "                    offset += 1\n",
    "            hits_and_misses += [target_tuple]\n",
    "\n",
    "        print(\"{}/{} hits with a {}s average reaction time\".format(len(time_offsets), len(lighton_idcs), sum(time_offsets)/len(time_offsets)))\n",
    "        \n",
    "        # remove all leading misses (participant still starting to move in the simulator)\n",
    "        while hits_and_misses[0][1] is False and bRemoveLeadingMisses:\n",
    "            total_leading_misses_removed += 1\n",
    "            hits_and_misses = hits_and_misses[1:]\n",
    "        \n",
    "        try: # do gaze classification\n",
    "            df2 = df1.copy()\n",
    "            df2['Lgaze_x'] = df1.GazeDir_LEFT.apply(lambda x: x[0])\n",
    "            df2['Lgaze_y'] = df1.GazeDir_LEFT.apply(lambda x: x[1])\n",
    "            df2['Lgaze_z'] = df1.GazeDir_LEFT.apply(lambda x: x[2])\n",
    "\n",
    "            df2['Rgaze_x'] = df1.GazeDir_RIGHT.apply(lambda x: x[0])\n",
    "            df2['Rgaze_y'] = df1.GazeDir_RIGHT.apply(lambda x: x[1])\n",
    "            df2['Rgaze_z'] = df1.GazeDir_RIGHT.apply(lambda x: x[2])\n",
    "\n",
    "            LgazeRaySplitDF = pd.DataFrame(df2[['Lgaze_x', 'Lgaze_y', 'Lgaze_z']])\n",
    "            LgazeRaySplitDF.rename(columns={'Lgaze_x': 'x', 'Lgaze_y': 'y', 'Lgaze_z': 'z'}, inplace=True)\n",
    "            LgazeRaySplitDF['timestamp'] = df2[\"TimeElapsed\"]\n",
    "            LgazeRaySplitDF['confidence'] = df2[\"EyeOpennessValid_LEFT\"].astype(bool) # remove all gazes where an eye was closed\n",
    "\n",
    "            RgazeRaySplitDF = pd.DataFrame(df2[['Rgaze_x', 'Rgaze_y', 'Rgaze_z']])\n",
    "            RgazeRaySplitDF.rename(columns={'Rgaze_x': 'x', 'Rgaze_y': 'y', 'Rgaze_z': 'z'}, inplace=True)\n",
    "            RgazeRaySplitDF['timestamp'] = df2[\"TimeElapsed\"]\n",
    "            RgazeRaySplitDF['confidence'] = df2[\"EyeOpennessValid_RIGHT\"].astype(bool) # remove all gazes where an eye was closed\n",
    "\n",
    "            velL = EyeClassifier.preprocess(LgazeRaySplitDF, dist_method='vector')\n",
    "            velL.velocity = velL.velocity.astype(float)\n",
    "            velR = EyeClassifier.preprocess(RgazeRaySplitDF, dist_method='vector')\n",
    "            velR.velocity = velR.velocity.astype(float)\n",
    "            model = EyeClassifier()\n",
    "            model.fit(eyes=(velL, velR))\n",
    "            labels, indiv_labels = model.predict(eyes=(velL, velR))\n",
    "            # print(labels)\n",
    "            # 0- fix, 1- sac, -1 -> noise\n",
    "            labels_unique = labels[1::2]\n",
    "            labels_unique.index = np.arange(1, len(labels_unique) + 1) # start index from 1 instead of 0\n",
    "            labels_np = labels_unique.to_numpy()\n",
    "            # add the labels to the original df:\n",
    "            recdf_with_labels = df2.join(labels_unique[\"label\"])\n",
    "        except:\n",
    "            print(\"something wrong happened during classification\")\n",
    "        # target tuples, go back and find labels\n",
    "        saccade_onsets = 0\n",
    "        fixation_onsets = 0\n",
    "        noise_onsets = 0\n",
    "        # fig, ax = plt.subplots()\n",
    "        graph_tuples = []\n",
    "\n",
    "        for target_tuple in hits_and_misses:\n",
    "            # for either hit or miss, go back and find the ofd\n",
    "            # check if you're in a fixation rn\n",
    "            if target_tuple[0].GazeValid_COMBINED==0: # check gaze validity at onset\n",
    "                continue\n",
    "            target_locindf = target_tuple[0].name\n",
    "            onset_gaze_event = recdf_with_labels.loc[target_locindf].label  \n",
    "            OFD = 0\n",
    "            pitch = recdf_with_labels.loc[target_locindf].gaze2target_pitch\n",
    "                   # + recdf_with_labels.loc[target_locindf].head2target_pitch\n",
    "            yaw = recdf_with_labels.loc[target_locindf].gaze2target_yaw \n",
    "                   # + recdf_with_labels.loc[target_locindf].head2target_yaw\n",
    "\n",
    "            if onset_gaze_event == 0:\n",
    "                fixation_onsets += 1\n",
    "                # go back and look at when this current fixation ends\n",
    "                # labels going back from current gaze\n",
    "                labels_upto_curr = recdf_with_labels.loc[target_locindf::-1].label \n",
    "                np.diff(labels_upto_curr)\n",
    "                labels_upto_curr = recdf_with_labels.loc[target_locindf::-1].label \n",
    "                label_diff = np.diff(labels_upto_curr)!=0\n",
    "                first_fixation_idx = target_locindf - np.argmax(label_diff)\n",
    "                OFD = recdf_with_labels.loc[target_locindf].TimeElapsed -\\\n",
    "                        recdf_with_labels.loc[first_fixation_idx].TimeElapsed\n",
    "\n",
    "                eccentricity = np.linalg.norm([recdf_with_labels.loc[target_locindf].gaze2target_pitch,\n",
    "                                              recdf_with_labels.loc[target_locindf].gaze2target_yaw])*180/np.pi\n",
    "                # ax.scatter(OFD, eccentricity, c='r' if target_tuple[1] is False else 'g')\n",
    "                graph_tuples += (OFD, eccentricity, target_tuple[1] is False, pitch, yaw)\n",
    "            elif onset_gaze_event == 1:\n",
    "                saccade_onsets += 1\n",
    "                OFD = 0        \n",
    "                eccentricity = np.linalg.norm([recdf_with_labels.loc[target_locindf].gaze2target_pitch,\n",
    "                                              recdf_with_labels.loc[target_locindf].gaze2target_yaw])*180/np.pi\n",
    "                # ax.scatter(OFD, eccentricity, c='r' if target_tuple[1] is False else 'g')\n",
    "                graph_tuples += (OFD, eccentricity, target_tuple[1] is False, pitch, yaw)\n",
    "            else:\n",
    "                noise_onsets += 1\n",
    "            # print(target_locindf, OFD)\n",
    "        print(\"{}/{} valid targets\".format(\n",
    "                fixation_onsets+saccade_onsets+noise_onsets,\n",
    "                len(hits_and_misses)))\n",
    "        print(\"{} fixation onsets, {} sacc, {} noise\".format(fixation_onsets, saccade_onsets, noise_onsets))\n",
    "\n",
    "        # #plt.xlim(0, )\n",
    "        # ax.set_ylim(-1, 60)\n",
    "        # ax.set_xlabel(\"Onset Fixation Duration (seconds)\")\n",
    "        # ax.set_ylabel(\"Eccentricity (degrees)\")\n",
    "        # ax.set_title(\"Hits/Misses on Gaze Eccentricity vs. OFD\")\n",
    "\n",
    "        # temp hack for henny meeting: save graph tuples TODO\n",
    "        with open(graph_data_filename, 'wb') as f:\n",
    "            pkl.dump(graph_tuples, f)\n",
    "        print(\"done writing \", graph_data_filename)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ba999dd-7f36-43e1-9f5a-0ed544f7976c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(total_leading_misses_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3593d4a3-acd4-4c60-806e-ba7ec6253404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e05e31b2-4f75-40f3-8445-867551a05b66",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Playground and Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e137fd2-da10-4dbe-b169-97747f140725",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'GazeDir_COMBINED'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19224/1157318999.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdf2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'gaze_x'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGazeDir_COMBINED\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'gaze_y'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGazeDir_COMBINED\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'gaze_z'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGazeDir_COMBINED\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\abhijat\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5485\u001b[0m         ):\n\u001b[0;32m   5486\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5487\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5489\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'GazeDir_COMBINED'"
     ]
    }
   ],
   "source": [
    "df2 = df1.copy()\n",
    "df2['gaze_x'] = df1.GazeDir_COMBINED.apply(lambda x: x[0])\n",
    "df2['gaze_y'] = df1.GazeDir_COMBINED.apply(lambda x: x[1])\n",
    "df2['gaze_z'] = df1.GazeDir_COMBINED.apply(lambda x: x[2])\n",
    "\n",
    "gaze_pitches = np.arctan2(df2.gaze_z, df2.gaze_x)*180/np.pi\n",
    "gaze_yaws = np.arctan2(df2.gaze_y, df2.gaze_x)*180/np.pi\n",
    "\n",
    "low_conf_gazeidcs = (gaze_pitches*gaze_yaws == 0)\n",
    "gaze_pitches = gaze_pitches[~low_conf_gazeidcs]\n",
    "gaze_yaws = gaze_yaws[~low_conf_gazeidcs]\n",
    "\n",
    "\n",
    "print(np.min(gaze_pitches),np.max(gaze_pitches))\n",
    "print(np.min(gaze_yaws),np.max(gaze_yaws))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1435bb0-ed68-43f7-ac7c-005d4a2088a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#gaze_pitches = gaze_pitches[1000:7000]\n",
    "#gaze_yaws = gaze_yaws[6000:7000]\n",
    "\n",
    "# Generate heat map of eye gaze wrt head pos\n",
    "plt.figure()\n",
    "plt.hist2d(gaze_yaws, gaze_pitches,\n",
    "           bins=50, cmap='hot')\n",
    "cb = plt.colorbar()\n",
    "cb.set_label('Number of points')\n",
    "plt.title('Heatmap of eye gaze wrt head direction')\n",
    "# plt.xlim(-20,20)\n",
    "# plt.ylim(-20,20)\n",
    "plt.xlabel('yaw')\n",
    "plt.ylabel('pitch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5115e652-b8de-4a4d-a2fe-3b1c1e5cdc0b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Hits and Misses calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da4c798-bcf9-49e5-9f4e-65c3e42915e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for every light appearance\n",
    "# find the nearest button press, before the next target appearance\n",
    "max_reaction_time_allowed = 5 #seconds\n",
    "time_offsets = []\n",
    "hits_and_misses = []\n",
    "for idx_num, lighton_idx in tqdm(enumerate(lighton_idcs)):\n",
    "    # while not found_buttonpress or lighton_idcs[idx_num+1]:\n",
    "    offset = 0\n",
    "    target_tuple = (df1.loc[lighton_idx], False)\n",
    "    while lighton_idx+offset < max(df1.index):\n",
    "        time_offset = df1.loc[lighton_idx+offset, \"TimeElapsed\"] - df1.loc[lighton_idx, \"TimeElapsed\"]   \n",
    "        if (df1.loc[lighton_idx+offset, \"ButtonPressed\"] == 1):\n",
    "            # print(\"{0:1.2f}s\".format(time_offset))\n",
    "            time_offsets += [time_offset]\n",
    "            target_tuple = (df1.loc[lighton_idx], df1.loc[lighton_idx+offset])\n",
    "            break\n",
    "        else:\n",
    "            if time_offset > max_reaction_time_allowed:\n",
    "                break\n",
    "            offset += 1\n",
    "    hits_and_misses += [target_tuple]\n",
    "    \n",
    "print(\"{}/{} hits with a {}s average reaction time\".format(len(time_offsets), len(lighton_idcs), sum(time_offsets)/len(time_offsets)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77994187-a699-4863-8b04-33c47b4316d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prelim analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0f1776-7cd4-4591-8c17-0b506964278c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preliminary analysis\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# plots of hits misses vs ecc\n",
    "for target_tuple in hits_and_misses:\n",
    "    target_response = True\n",
    "    if target_tuple[1] is False:\n",
    "        # miss\n",
    "        target_response = False\n",
    "        pass\n",
    "    else:\n",
    "        # hits\n",
    "        pass\n",
    "        # print(target_tuple[1].ButtonPressed)\n",
    "    ax.scatter(target_tuple[0].gaze2target_yaw*180/np.pi,\n",
    "               target_tuple[0].gaze2target_pitch*180/np.pi,\n",
    "               c='g' if target_response else 'r')\n",
    "    ax.set_title(\"Hits/Misses vs. Eccentricity\\n(Pitch and Yaw of Target from EYE Gaze during onset)\")\n",
    "    \n",
    "    # ax.scatter(target_tuple[0].head2target_yaw*180/np.pi, target_tuple[0].head2target_pitch*180/np.pi, c='g' if target_response else 'r')\n",
    "    # ax.set_title(\"Hits/Misses vs. Eccentricity\\n(Pitch and Yaw of Target from HEAD Gaze during onset)\")\n",
    "    \n",
    "    ax.set_xlabel(\"yaw (degrees)\")\n",
    "    ax.set_ylabel(\"pitch (degrees)\")\n",
    "    ax.set_xlim(-60, 60)\n",
    "    ax.set_ylim(-40, 60)\n",
    "    ax.set_aspect('equal')\n",
    "    # ax.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780cef8f-dbb5-4624-abba-77c9f0e26083",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Gaze event detection (eye gaze vector only)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8e6e9d-530a-40af-88fb-cbee6164c698",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca14dcd-7e84-4824-9160-76a413ff633c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a1367e-8914-4250-8399-bd604f7919b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae73a96-7093-46c7-aada-85e37db92c8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15e4155-1d73-4f99-b9f0-ee6477b74520",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num fixation total pts: \", np.sum(labels_np[:,2]))\n",
    "print(\"Num saccades total pts: \", np.sum(labels_np[:,3]))\n",
    "print(\"Num noise total pts: \", np.sum(labels_np[:,4]))\n",
    "print()\n",
    "# filter the consecutives\n",
    "print(\"Num fixations: \", np.sum(np.diff(labels_np[:, 2]) == 1))\n",
    "print(\"Num saccades: \", np.sum(np.diff(labels_np[:, 3]) == 1))\n",
    "print(\"Num noise: \", np.sum(np.diff(labels_np[:, 4]) == 1))\n",
    "print(\"Num LightOns: \", num_targets_spawned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f32de9-2469-46ef-a40f-1f24fe7c7fc0",
   "metadata": {},
   "source": [
    "## OFD analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8955ae34-47ee-439e-a9f3-340dfd6c8d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target tuples, go back and find labels\n",
    "saccade_onsets = 0\n",
    "fixation_onsets = 0\n",
    "noise_onsets = 0\n",
    "# fig, ax = plt.subplots()\n",
    "graph_tuples = []\n",
    "\n",
    "for target_tuple in hits_and_misses:\n",
    "    # for either hit or miss, go back and find the ofd\n",
    "    # check if you're in a fixation rn\n",
    "    if target_tuple[0].GazeValid_COMBINED==0: # check gaze validity \n",
    "        continue\n",
    "    target_locindf = target_tuple[0].name\n",
    "    onset_gaze_event = recdf_with_labels.loc[target_locindf].label  \n",
    "    OFD = 0\n",
    "    pitch = recdf_with_labels.loc[target_locindf].gaze2target_pitch\n",
    "           # + recdf_with_labels.loc[target_locindf].head2target_pitch\n",
    "    yaw = recdf_with_labels.loc[target_locindf].gaze2target_yaw \n",
    "           # + recdf_with_labels.loc[target_locindf].head2target_yaw\n",
    "    \n",
    "    if onset_gaze_event == 0:\n",
    "        fixation_onsets += 1\n",
    "        # go back and look at when this current fixation ends\n",
    "        # labels going back from current gaze\n",
    "        labels_upto_curr = recdf_with_labels.loc[target_locindf::-1].label \n",
    "        np.diff(labels_upto_curr)\n",
    "        labels_upto_curr = recdf_with_labels.loc[target_locindf::-1].label \n",
    "        label_diff = np.diff(labels_upto_curr)!=0\n",
    "        first_fixation_idx = target_locindf - np.argmax(label_diff)\n",
    "        OFD = recdf_with_labels.loc[target_locindf].TimeElapsed -\\\n",
    "                recdf_with_labels.loc[first_fixation_idx].TimeElapsed\n",
    "        \n",
    "        eccentricity = np.linalg.norm([recdf_with_labels.loc[target_locindf].gaze2target_pitch,\n",
    "                                      recdf_with_labels.loc[target_locindf].gaze2target_yaw])*180/np.pi\n",
    "        # ax.scatter(OFD, eccentricity, c='r' if target_tuple[1] is False else 'g')\n",
    "        graph_tuples += (OFD, eccentricity, target_tuple[1] is False, pitch, yaw)\n",
    "    elif onset_gaze_event == 1:\n",
    "        saccade_onsets += 1\n",
    "        OFD = 0        \n",
    "        eccentricity = np.linalg.norm([recdf_with_labels.loc[target_locindf].gaze2target_pitch,\n",
    "                                      recdf_with_labels.loc[target_locindf].gaze2target_yaw])*180/np.pi\n",
    "        # ax.scatter(OFD, eccentricity, c='r' if target_tuple[1] is False else 'g')\n",
    "        graph_tuples += (OFD, eccentricity, target_tuple[1] is False, pitch, yaw)\n",
    "    else:\n",
    "        noise_onsets += 1\n",
    "    # print(target_locindf, OFD)\n",
    "print(\"{}/{} valid targets\".format(\n",
    "        fixation_onsets+saccade_onsets+noise_onsets,\n",
    "        len(hits_and_misses)))\n",
    "print(\"{} fixation onsets, {} sacc, {} noise\".format(fixation_onsets, saccade_onsets, noise_onsets))\n",
    "\n",
    "# #plt.xlim(0, )\n",
    "# ax.set_ylim(-1, 60)\n",
    "# ax.set_xlabel(\"Onset Fixation Duration (seconds)\")\n",
    "# ax.set_ylabel(\"Eccentricity (degrees)\")\n",
    "# ax.set_title(\"Hits/Misses on Gaze Eccentricity vs. OFD\")\n",
    "\n",
    "# temp hack for henny meeting: save graph tuples\n",
    "graph_data_filename = Path(\"temp_data\").joinpath(recording_name+\"_OFDvEcc.pkl\")\n",
    "with open(graph_data_filename, 'wb') as f:\n",
    "    pkl.dump(graph_tuples, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26187812-5481-4646-8d4c-e849265d0f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp hack for henny meeting: save graph tuples\n",
    "graph_data_filename = Path(\"temp_data\").joinpath(recording_name+\"_OFDvEcc.pkl\")\n",
    "with open(graph_data_filename, 'wb') as f:\n",
    "    pkl.dump(graph_tuples, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d7a80c-4599-4ff9-a2f8-2eb93d071c01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
